{"cord_uid": "fl6wlhjs", "sourcedb": "PMC", "sourceid": "PMC2203979", "divid": "58", "text": "The one - step prediction error process , { E k , t } is where we define c k , 0 = 1 and c k , j = - b k , j for j = 1 , . . . , m . The process { E k , t } is a filtering of { X k , t } and so if { X k , t } is stationary , by the linear time invariant filtering result for stationary processes , { E k , t } is also stationary ( [ 18 ] , Theorem 4 . 10 . 1 ) . Moreover for large enough m , if { X k , t } is an invertible time series process then we can approximate { X k , t } by an autoregressive , AR ( m ) process ( [ 18 ] , Theorem 4 . 4 . 3 ) . Using this approximation we can argue that { E k , t } is approximately a mean zero Gaussian independent and identically distributed process with variance gamma \u03b3 X , k ( 0 ) . Let { a 0 , . . . , a L - 1 } denote a pre - specified filter of width L . We define the detection process { D k , t } by filtering the error process { E k , t } using this filter . Thus , By the filtering result for stationary processes , stationarity of { X k , t } implies that { D k , t } is also a stationary process .", "project": "cdlai_CORD-19", "denotations": []}